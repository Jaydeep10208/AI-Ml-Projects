import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.cluster import KMeans
from kneed import KneeLocator
from sklearn.metrics import silhouette_score
from sklearn.cluster import AgglomerativeClustering
from kneed import KneeLocator


df = pd.read_csv("smartcart_customers.csv") 


# df.info()
df.isnull().sum()





# 
df = df.drop(columns = "ID")
df.head()

df["Income"] = df["Income"].fillna(df["Income"].median())



df.columns


# Age
df["Age"] = 2026  - df["Year_Birth"]




df["Dt_Customer"] = pd.to_datetime(df["Dt_Customer"], dayfirst = True)
refernce_date = df["Dt_Customer"].max()

df["Customer_Tenure_Days"] = (refernce_date - df["Dt_Customer"]).dt.days


df.columns


# Spending

df["Total_Spending"] = df["MntWines"] + df["MntFruits"] + df["MntMeatProducts"] + df["MntFishProducts"] + df["MntSweetProducts"] + df["MntGoldProds"] 
df["Total_Childeren"] = df["Kidhome"] + df["Teenhome"]


# df["Education"].value_counts()

# Undergraduate , Gradute , Postgraduate

df["Education"] = df["Education"].replace({
    "Basic" : "Undergraduate",
    "2n Cycle" : "Undergraduate",
    "Graduation" : "Graduate",
    "Master" : "Postgraduate",
    "PhD" : "Postgraduate"
})


df["Education"].value_counts()


df["Marital_Status"].value_counts()


df["Living_With"] = df["Marital_Status"].replace({
    "Married": "Partner", "Together": "Partner",
    "Single": "Alone", "Divorced": "Alone",
    "Widow": "Alone", "Absurd": "Alone", "YOLO": "Alone"
})


df["Living_With"].value_counts()





cols = ["Year_Birth", "Marital_Status", "Kidhome", "Teenhome", "Dt_Customer"]
spending_cols = ["MntWines", "MntFruits", "MntMeatProducts", "MntFishProducts", "MntSweetProducts", "MntGoldProds"]

cols_to_drop = cols + spending_cols

dfc = df.drop(columns=cols_to_drop)
dfc


dfc.info()


cols = ["Income","Recency" ,"Age", "Total_Spending" , "Total_Childeren"]

# relative pair plot

sns.pairplot(df_cleaned[cols])


# Remove outliers

print("data size with outliers:", len(df_cleaned))

df_cleaned = df_cleaned[ (df_cleaned["Age"] < 90) ]
df_cleaned = df_cleaned[ (df_cleaned["Income"] < 600_000) ]

print("data size without outliers:", len(df_cleaned))


# Remove outliers

print("data size with outliers:", len(df_cleaned))

df_cleaned = df_cleaned[ (df_cleaned["Age"] < 90) ]
df_cleaned = df_cleaned[ (df_cleaned["Income"] < 600_000) ]

print("data size without outliers:", len(df_cleaned))


corr = dfc.corr(numeric_only = True)



plt.figure(figsize = (8,6))
sns.heatmap(
    corr ,
    annot = True ,
    annot_kws = {"size":8},
    cmap = "coolwarm" 
)


dfc.shape
dfc.sample(10)


ohe = OneHotEncoder()

cat_cols = ["Education", "Living_With"]
enc = ohe.fit_transform(dfc[cat_cols])

pd.DataFrame(enc_cols.toarray() , columns = ohe.get_feature_names_out(cat_cols))


ohe = OneHotEncoder()

cat_cols = ["Education", "Living_With"]

enc_cols = ohe.fit_transform(df_cleaned[cat_cols])


enc_df = pd.DataFrame(enc_cols.toarray(), columns=ohe.get_feature_names_out(cat_cols), index=df_cleaned.index)


df_encoded = pd.concat([df_cleaned.drop(columns=cat_cols),enc_df], axis=1)


X = df_encoded
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded)

X_scaled.shape


pca = PCA(n_components = 3)
X_pca = pca.fit_transform(X_scaled)


pca.explained_variance_ratio_





plt.scatter(x = X_pca[:, 0],y = X_pca[:, 1],)

# plt.set_xlabel("PCA1")
# plt.set_ylabel("PCA2")
# plt.set_title("2d projection")


# plot
fig = plt.figure(figsize=(8, 6))

ax = fig.add_subplot(111, projection="3d")

ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2])

ax.set_xlabel("PCA1")
ax.set_ylabel("PCA2")
ax.set_zlabel("PCA3")
ax.set_title("3d projection")



wcss  = []
for k in range(1,11):
    kmeans = KMeans(n_clusters=k,random_state = 42)
    kmeans.fit_predict(X_pca)
    wcss.append(kmeans.inertia_)

knee = KneeLocator(range(1,11) , wcss , curve = "convex",direction = "decreasing")
optimal_k = knee.elbow
print("K = ",optimal_k)


plt.plot(range(1, 11), wcss, marker='o')
# plt.xlabel("K")
# plt.ylabel("WCSS")







from sklearn.metrics import silhouette_score

score = []

for k in range(2,11):
    kmeans = KMeans(n_clusters = k ,  random_state = 42)
    labels  = kmeans.fit_predict(X_pca)
    n = silhouette_score(X_pca, labels)
    score.append(n)

plt.plot(range(2, 11), score, marker='o')


k_range = range(2,11)

# plt.plot(range(2, 11), score, marker='o')
fig,ax1 = plt.subplots(figsize = (8,6))
ax1.plot(k_range,wcss[:len(k_range)] ,marker = 'o', color = "blue" )
ax1.set_xlabel("k")
ax1.set_ylabel("WCSS")
ax2 = ax1.twinx()
ax2.plot(k_range, score[:len(k_range)], marker = 'x' ,color = 'red', linestyle = '--' )


# K_means

kmeans = KMeans(n_clusters = 4 , random_state= 42)
kmeans_labels = kmeans.fit_predict(X_pca)


fig = plt.figure(figsize=(8, 6))

ax = fig.add_subplot(111, projection="3d")

ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c= kmeans_labels)

ax.set_xlabel("PCA1")
ax.set_ylabel("PCA2")
ax.set_zlabel("PCA3")
ax.set_title("3d projection")


agg_clf = AgglomerativeClustering(n_clusters=4, linkage="ward")
labels_agg = agg_clf.fit_predict(X_pca)
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection="3d")
ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=labels_agg)





# df_cleaned = df_cleaned.drop("label", axis  =1)
X["cluster"] = labels_agg



pal = ["blue","red","yellow","green"]
sns.countplot(x = X["cluster"],palette = pal, hue = X["cluster"])


sns.scatterplot(x = df_cleaned["Total_Spending"] , y = df_cleaned["Income"], hue = df_cleaned["cluster"],palette = pal)


df_cleaned.columns


cluster_summary = X.groupby("cluster").mean()
print(cluster_summary)
